# fix_complete.py
import os

# 1. Corrigir detecÃ§Ã£o de modelos no local_llm.py
print("ğŸ”§ Corrigindo detecÃ§Ã£o de modelos...")

llm_code = '''# models/local_llm.py
import asyncio
import logging
import ollama
from typing import Optional, Dict, Any, List
from config.settings import ModelConfig

class LocalLLM:
    def __init__(self, config: ModelConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.client = ollama.AsyncClient()
        self.conversation_history: List[Dict[str, str]] = []
        
    async def initialize(self):
        try:
            self.logger.info(f"Inicializando modelo {self.config.model_name}...")
            
            # Verificar se o modelo estÃ¡ disponÃ­vel
            models = await self.list_available_models()
            
            # CORREÃ‡ÃƒO: Extrair nomes dos modelos corretamente
            model_names = []
            for model in models:
                if hasattr(model, 'model'):
                    model_names.append(model.model)
                elif isinstance(model, dict) and 'model' in model:
                    model_names.append(model['model'])
            
            self.logger.info(f"Modelos disponÃ­veis: {model_names}")
            
            # Verificar se o modelo desejado existe
            if self.config.model_name in model_names:
                self.logger.info(f"Modelo {self.config.model_name} encontrado!")
            else:
                self.logger.warning(f"Modelo {self.config.model_name} nÃ£o encontrado nos modelos: {model_names}")
                # Tentar usar o primeiro modelo Llama disponÃ­vel
                for name in model_names:
                    if "llama" in name.lower():
                        self.logger.info(f"Usando modelo alternativo: {name}")
                        self.config.model_name = name
                        break
            
            # Testar o modelo
            await self.test_model()
            
            self.logger.info("Modelo inicializado com sucesso!")
            
        except Exception as e:
            self.logger.error(f"Erro ao inicializar modelo: {e}")
            # NÃ£o fazer raise, continuar
    
    async def list_available_models(self) -> List[Any]:
        try:
            response = await self.client.list()
            models = response.get('models', [])
            return models
        except Exception as e:
            self.logger.error(f"Erro ao listar modelos: {e}")
            return []
    
    async def test_model(self):
        try:
            test_prompt = "Diga apenas 'Modelo funcionando' em portuguÃªs."
            response = await self.generate_response(test_prompt, use_history=False)
            
            if response and "erro" not in response.lower():
                self.logger.info(f"Teste do modelo bem-sucedido!")
            else:
                self.logger.warning(f"Modelo respondeu com: {response}")
                
        except Exception as e:
            self.logger.error(f"Erro no teste do modelo: {e}")
    
    async def generate_response(self, prompt: str, use_history: bool = True) -> Optional[str]:
        try:
            # Preparar mensagens
            messages = []
            
            if use_history and self.conversation_history:
                # Manter apenas as Ãºltimas conversas
                recent_history = self.conversation_history[-4:]  # Ainda menor
                messages.extend(recent_history)
            
            # Adicionar prompt atual
            messages.append({
                'role': 'user',
                'content': prompt
            })
            
            # Gerar resposta
            response = await self.client.chat(
                model=self.config.model_name,
                messages=messages,
                options={
                    'temperature': self.config.temperature,
                    'num_predict': self.config.max_tokens,
                    'top_p': 0.9,
                    'repeat_penalty': 1.1
                }
            )
            
            if response and 'message' in response and 'content' in response['message']:
                assistant_message = response['message']['content'].strip()
                
                # Adicionar ao histÃ³rico
                if use_history:
                    self.conversation_history.append({
                        'role': 'user',
                        'content': prompt
                    })
                    self.conversation_history.append({
                        'role': 'assistant',
                        'content': assistant_message
                    })
                    
                    # Limitar histÃ³rico
                    if len(self.conversation_history) > 8:
                        self.conversation_history = self.conversation_history[-6:]
                
                return assistant_message
            else:
                self.logger.error(f"Resposta invÃ¡lida: {response}")
                return "Desculpe, nÃ£o consegui gerar uma resposta adequada."
                
        except Exception as e:
            self.logger.error(f"Erro ao gerar resposta: {e}")
            return f"Desculpe, houve um erro: {str(e)[:100]}"
    
    def clear_history(self):
        self.conversation_history = []
        self.logger.info("HistÃ³rico limpo")
    
    def get_model_info(self) -> Dict[str, Any]:
        return {
            'model_name': self.config.model_name,
            'max_tokens': self.config.max_tokens,
            'temperature': self.config.temperature,
            'history_length': len(self.conversation_history)
        }
'''

# 2. Adicionar input de texto + melhorar loop de escuta
agent_code = '''# core/agent.py
import asyncio
import logging
import threading
from datetime import datetime
from typing import Optional, Dict, Any

from core.speech_to_text import SpeechToText
from core.text_to_speech import TextToSpeech
from core.conversation import ConversationManager
from memory.user_profile import UserProfile
from memory.database import DatabaseManager
from models.local_llm import LocalLLM
from config.settings import AgentConfig

class AIAgent:
    """Classe principal do agente de IA"""
    
    def __init__(self, config: AgentConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # Componentes principais
        self.stt: Optional[SpeechToText] = None
        self.tts: Optional[TextToSpeech] = None
        self.llm: Optional[LocalLLM] = None
        self.conversation_manager: Optional[ConversationManager] = None
        self.user_profile: Optional[UserProfile] = None
        self.database: Optional[DatabaseManager] = None
        
        # Estado do agente
        self.is_listening = False
        self.is_speaking = False
        self.is_running = False
        
    async def initialize(self):
        """Inicializa todos os componentes do agente"""
        self.logger.info("Inicializando componentes do agente...")
        
        try:
            # Inicializar banco de dados
            self.database = DatabaseManager(self.config.database)
            await self.database.initialize()
            
            # Inicializar perfil do usuÃ¡rio
            self.user_profile = UserProfile(self.database)
            await self.user_profile.load_profile()
            
            # Inicializar modelo de IA
            self.llm = LocalLLM(self.config.model)
            await self.llm.initialize()
            
            # Inicializar componentes de voz
            self.stt = SpeechToText(self.config.voice)
            self.tts = TextToSpeech(self.config.voice)
            
            # Inicializar gerenciador de conversas
            self.conversation_manager = ConversationManager(
                self.database, 
                self.user_profile,
                self.config
            )
            
            self.logger.info("Todos os componentes inicializados com sucesso!")
            
        except Exception as e:
            self.logger.error(f"Erro ao inicializar agente: {e}")
            raise
    
    async def run(self):
        """Loop principal do agente"""
        self.is_running = True
        
        # SaudaÃ§Ã£o inicial
        user_name = self.user_profile.get_user_name()
        greeting = f"OlÃ¡ {user_name}! Sou a {self.config.name}, sua assistente pessoal. Como posso ajudÃ¡-lo hoje?"
        await self.speak(greeting)
        
        print("\\n" + "="*60)
        print("ğŸ¤– AGENTE ATIVO - Escolha como interagir:")
        print("ğŸ¤ [ENTER] para falar (reconhecimento de voz)")
        print("âŒ¨ï¸  [TEXTO] digite sua mensagem + ENTER")
        print("âŒ [sair] para encerrar")
        print("="*60 + "\\n")
        
        try:
            while self.is_running:
                # Aguardar input do usuÃ¡rio
                user_input = await self.get_user_input()
                
                if user_input:
                    # Verificar comandos especiais
                    if self.check_exit_command(user_input):
                        break
                    
                    # Processar entrada do usuÃ¡rio
                    response = await self.process_input(user_input)
                    
                    # Responder ao usuÃ¡rio
                    if response:
                        await self.speak(response)
                
        except KeyboardInterrupt:
            print("\\nâš ï¸ InterrupÃ§Ã£o detectada...")
        finally:
            await self.shutdown()
    
    async def get_user_input(self) -> Optional[str]:
        """ObtÃ©m input do usuÃ¡rio (texto ou voz)"""
        try:
            print("\\nğŸ’¬ Sua vez (ENTER=voz, texto+ENTER=texto):")
            
            # Executar input em thread separada
            loop = asyncio.get_event_loop()
            user_text = await loop.run_in_executor(None, input, ">>> ")
            
            if user_text.strip():
                # Input de texto
                print(f"ğŸ‘¤ VocÃª (texto): {user_text}")
                await self.conversation_manager.add_message("user", user_text)
                return user_text.strip()
            else:
                # Input de voz
                print("ğŸ¤ Escutando... (fale agora, 5 segundos)")
                voice_input = await self.listen()
                return voice_input
                
        except Exception as e:
            self.logger.error(f"Erro ao obter input: {e}")
            return None
    
    async def listen(self) -> Optional[str]:
        """Escuta entrada de voz do usuÃ¡rio"""
        if self.is_speaking or self.is_listening:
            return None
            
        self.is_listening = True
        try:
            # Usar reconhecimento de voz
            text = await self.stt.listen()
            if text:
                self.logger.info(f"UsuÃ¡rio disse: {text}")
                print(f"ğŸ‘¤ VocÃª (voz): {text}")
                # Salvar na conversa
                await self.conversation_manager.add_message("user", text)
            else:
                print("âŒ NÃ£o consegui ouvir nada")
            return text
        except Exception as e:
            self.logger.error(f"Erro no reconhecimento de voz: {e}")
            print(f"âŒ Erro no reconhecimento: {e}")
            return None
        finally:
            self.is_listening = False
    
    async def speak(self, text: str):
        """Fala o texto fornecido"""
        if self.is_speaking:
            return
            
        self.is_speaking = True
        try:
            self.logger.info(f"Assistente: {text}")
            print(f"\\nğŸ¤– ARIA: {text}")
            await self.tts.speak(text)
            # Salvar na conversa
            await self.conversation_manager.add_message("assistant", text)
        except Exception as e:
            self.logger.error(f"Erro na sÃ­ntese de voz: {e}")
            print(f"âŒ Erro na fala: {e}")
        finally:
            self.is_speaking = False
    
    async def process_input(self, user_input: str) -> Optional[str]:
        """Processa a entrada do usuÃ¡rio e gera resposta"""
        try:
            print("ğŸ§  Processando...")
            
            # Extrair informaÃ§Ãµes pessoais do usuÃ¡rio
            await self.user_profile.extract_and_update_info(user_input)
            
            # Obter contexto da conversa
            context = await self.conversation_manager.get_context()
            
            # Criar prompt personalizado
            prompt = self.create_personalized_prompt(user_input, context)
            
            # Gerar resposta usando o modelo local
            response = await self.llm.generate_response(prompt)
            
            return response
            
        except Exception as e:
            self.logger.error(f"Erro ao processar entrada: {e}")
            return "Desculpe, houve um erro interno. Pode repetir por favor?"
    
    def create_personalized_prompt(self, user_input: str, context: str) -> str:
        """Cria prompt personalizado baseado no perfil do usuÃ¡rio"""
        user_info = self.user_profile.get_summary()
        
        prompt = f"""VocÃª Ã© {self.config.name}, uma assistente pessoal IA {self.config.personality}.

INFORMAÃ‡Ã•ES DO USUÃRIO:
{user_info}

ENTRADA DO USUÃRIO: {user_input}

Responda de forma natural, amigÃ¡vel e concisa (mÃ¡ximo 2-3 frases). Se o usuÃ¡rio compartilhar informaÃ§Ãµes pessoais, reconheÃ§a isso.

RESPOSTA:"""
        
        return prompt
    
    def check_exit_command(self, text: str) -> bool:
        """Verifica se o usuÃ¡rio quer sair"""
        exit_commands = ["sair", "tchau", "atÃ© logo", "encerrar", "parar", "quit", "exit"]
        return any(cmd in text.lower() for cmd in exit_commands)
    
    async def shutdown(self):
        """Encerra o agente de forma limpa"""
        print("\\nğŸ”„ Encerrando agente...")
        self.is_running = False
        
        # Salvar dados do usuÃ¡rio
        if self.user_profile:
            await self.user_profile.save_profile()
        
        # Fechar conexÃµes
        if self.database:
            await self.database.close()
        
        # Despedida
        print("ğŸ‘‹ AtÃ© logo! Obrigada por usar a ARIA!")
        self.logger.info("Agente encerrado com sucesso!")
'''

# Salvar arquivos corrigidos
print("ğŸ“ Atualizando models/local_llm.py...")
with open("models/local_llm.py", "w", encoding="utf-8") as f:
    f.write(llm_code)

print("ğŸ“ Atualizando core/agent.py...")
with open("core/agent.py", "w", encoding="utf-8") as f:
    f.write(agent_code)

print("âœ… CorreÃ§Ãµes aplicadas!")
print("")
print("ğŸ¯ MUDANÃ‡AS FEITAS:")
print("â€¢ âœ… DetecÃ§Ã£o correta de modelos Ollama")
print("â€¢ âœ… Input por TEXTO + ENTER")
print("â€¢ âœ… Input por VOZ (sÃ³ ENTER)")
print("â€¢ âœ… Interface melhorada")
print("â€¢ âœ… Tratamento de erros melhorado")
print("")
print("ğŸš€ Execute: python main.py")
print("ğŸ’¡ Agora vocÃª pode digitar OU falar!")